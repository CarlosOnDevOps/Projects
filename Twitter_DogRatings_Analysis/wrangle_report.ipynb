{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d283c284",
   "metadata": {},
   "source": [
    "# Tales of Tails: Analyzing Dog Ratings on Twitter\n",
    "#### Prepared by: Jose Carlos Moreno Ramirez\n",
    "#### Institution: Western Govornors University\n",
    "#### Course: Data Wrangling - D309 \n",
    "#### Project: Wrangle and Analyze Data\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "This report's goal is to go into detail about the data wrangling I did for the \"We Rate Dogs\" project. Data from numerous sources were gathered, evaluated, and cleaned as part of this extensive process to guarantee that it was ready for further analysis and visualization.\n",
    "\n",
    "---\n",
    "### Data Gathering\n",
    "Working with and extracting data from three separate sources was required to compile all the information required for this project:\n",
    "\n",
    "1. Twitter Archive: `twitter_archive_enhanced.csv`, a CSV file, used as the primary dataset. This dataset includes text, dog ratings, timestamps, tweet IDs, and tweet content.\n",
    "\n",
    "2. Image Predictions: A programmatic URL was used to download a file with the name `image_predictions.tsv`. The dog breed seen in each tweet's image is predicted in this dataset.\n",
    "\n",
    "3. Twitter API: More information, such as favorite and retweet counts, was gathered via the Twitter API and saved in the text file `tweet_json.txt`.\n",
    ">*Note: Unfortunately, the Twitter API is locked behind a paywall after Elon Musk took over as Twitter CEO. Therefor, Western Govornors University provided me [the student]  with a text file containing all the tweet data that would have otherwise been retrieved from the API.* \n",
    "\n",
    "---\n",
    "### Data Assessment\n",
    "Before cleaning the data, I analyzed the datasets to identify quality and tidiness issues. The assessment revealed the following key points:\n",
    "\n",
    "1. **Archive Table**:\n",
    "    - Adjust the datatype for certain columns to ensure consistency.\n",
    "    - Address missing data in the DataFrame.\n",
    "    - Replace missing values, currently represented as \"None,\" with appropriate null values in the name column.\n",
    "    - Review and correct expanded URLs that contain multiple URLs.\n",
    "    - Improve the formatting of the `text` column.\n",
    "    - Remove retweets from the data.\n",
    "    - Address HTML tags in the `source` column.\n",
    "\n",
    "2. **Image Table**:\n",
    "    - Standardize the capitalization for `P1`, `P2`, and `P3` labels where necessary.\n",
    "    - Ensure proper formatting for `P1`, `P2`, and `P3` columns within the image table.\n",
    "    \n",
    "3. **Tweet Table**:\n",
    "    - Extract the date component from the `date_created` column.\n",
    "    - Consider renaming the `date_created` column to `timestamp` for consistency across datasets.\n",
    "    \n",
    "4. **Tidiness issues**:\n",
    "    - Combine multiple DataFrames to ensure that all tweet-related information is in one place for analysis.\n",
    "    - Combine the dog stage information spread across four columns (`doggo`, `floofer`, `pupper`, and `puppo`) into a single stage column.\n",
    "\n",
    "---\n",
    "\n",
    "### Data Cleaning\n",
    "The data cleaning procedure took care of the found quality and structure concerns. The actions taken were as follows:\n",
    "\n",
    "1. Changed the data types for some columns.\n",
    "2. Handled missing data within their applicable DataFrames.\n",
    "3. Replaced missing data with acceptable null values.\n",
    "4. Efficiently extracted data values separated by the pipe delimiter.\n",
    "5. Standardized the capitilization for columns in the Image table where necessary.\n",
    "6. Improved the formatting of the `text` column in the Archive table.\n",
    "7. Extracted month, day, year components from the `date_created` column.\n",
    "8. Renamed the `created_at` column to `timestamp` for consistency across datasets.\n",
    "9. Ensured proper formatting for `p1`, `p2`, and `p3` columns within the Image table.\n",
    "10. Eliminated HTML tags from the `source` column in the Archive table.\n",
    "\n",
    "---\n",
    "### Data Storage\n",
    "The method I applied to storing all the collected data is as follows:\n",
    "1. I made copies of each DataFrame to manipulate freely.\n",
    "2. Then, I combined all the DataFrames into a single DataFrame named `master_df`\n",
    "3. Finally, I saved the dataset in a CSV file named `twitter_master_archive.csv`.\n",
    "\n",
    "---\n",
    "### Conclusion\n",
    "For the \"We Rate Dogs\" project, data had to be wrangled from a variety of sources, evaluated for quality and organization, and then cleaned up in order to be ready for analysis. I was able to create interesting graphics using the data thanks to the clean datasets that were produced and the cleansed Twitter API data.\n",
    "\n",
    "---\n",
    "### References\n",
    "Any references I utilized are included right after the cellblock output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c38839",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3902259",
   "metadata": {},
   "source": [
    "END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
